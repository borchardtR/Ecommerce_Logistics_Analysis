{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecommerce Logistics Analysis, Part 5\n",
    "### Geographic Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from table_audit import table_audit_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Create context manager to handle connection to SQLite database and return dataframe from query\n",
    "def run_query(q):\n",
    "    with sqlite3.connect('data/ecommerce.db') as conn:\n",
    "        return pd.read_sql_query(q,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a schema summarizing the relationships between the tables in the database I created in Part 1:\n",
    "![title](images/schema_rearranged_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values investigation\n",
    "\n",
    "In this section, dealing with latitude and longitude values of customers and sellers. \n",
    "Looking at shipments that were actually delivered (order_status='delivered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-57626f7925c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m '''\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-48171e3a4f91>\u001b[0m in \u001b[0;36mrun_query\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Create context manager to handle connection to SQLite database and return dataframe from query\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/ecommerce.db'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "q1 = '''\n",
    "SELECT \n",
    "    c.*,\n",
    "    g.geolocation_lat c_lat,\n",
    "    g.geolocation_lng c_lng,\n",
    "    merged.*,\n",
    "    s.*,\n",
    "    g2.geolocation_lat s_lat,\n",
    "    g2.geolocation_lng s_lng\n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM orders_modified om\n",
    "    LEFT JOIN order_items_modified oim ON oim.order_id=om.order_id\n",
    "    GROUP BY om.order_id\n",
    "    ) as merged\n",
    "LEFT JOIN customers c ON c.customer_id = merged.customer_id\n",
    "LEFT JOIN geolocation g ON g.geolocation_zip_code = c.customer_zip_code_prefix\n",
    "LEFT JOIN sellers s ON s.seller_id = merged.seller_id\n",
    "LEFT JOIN geolocation g2 ON g2.geolocation_zip_code = s.seller_zip_code_prefix\n",
    "'''\n",
    "\n",
    "df1 = run_query(q1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_audit_function(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = '''\n",
    "SELECT \n",
    "    c.*,\n",
    "    g.geolocation_lat c_lat,\n",
    "    g.geolocation_lng c_lng,\n",
    "    merged.*,\n",
    "    s.*,\n",
    "    g2.geolocation_lat s_lat,\n",
    "    g2.geolocation_lng s_lng\n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM orders_modified om\n",
    "    LEFT JOIN order_items_modified oim ON oim.order_id=om.order_id\n",
    "    GROUP BY om.order_id\n",
    "    ) as merged\n",
    "LEFT JOIN customers c ON c.customer_id = merged.customer_id\n",
    "LEFT JOIN geolocation g ON g.geolocation_zip_code = c.customer_zip_code_prefix\n",
    "LEFT JOIN sellers s ON s.seller_id = merged.seller_id\n",
    "LEFT JOIN geolocation g2 ON g2.geolocation_zip_code = s.seller_zip_code_prefix\n",
    "WHERE merged.order_status='delivered' AND length(c_lat)>0 AND length(s_lat)>0\n",
    "'''\n",
    "\n",
    "df2 = run_query(q2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_audit_function(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of missing values investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to drop repeated columns: customer_id, order_id, seller_id\n",
    "geo_df = df2\n",
    "\n",
    "# df.columns.duplicated returns list of booleans, false if not repeated up to that point and true if repeated\n",
    "# Use '~' to flip trues-> false and false-> trues\n",
    "# End result is df w/ no repeated column names\n",
    "geo_df = geo_df.loc[:,~geo_df.columns.duplicated()]\n",
    "\n",
    "geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of orders: ', len(geo_df['order_id']))\n",
    "print('Number of customers: ', len(geo_df['customer_unique_id'].unique()))\n",
    "print('Number of sellers: ', len(geo_df['seller_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mpl_toolkits.basemap import Basemap\n",
    "#from matplotlib.collections import LineCollection\n",
    "\n",
    "#fig = plt.figure(figsize=(15,10))\n",
    "#ax1 = fig.add_subplot(121)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "#map_customers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=80, llcrnrlon=-130, urcrnrlon=30)\n",
    "#map_customers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "\n",
    "#map_customers.drawstates(linewidth=0.5)\n",
    "#map_customers.drawcoastlines(linewidth=0.5)\n",
    "#map_customers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "#customers_x, customers_y = map_customers(list(geo_df['c_lng']), list(geo_df['c_lat']))\n",
    "\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "#ax1.scatter(customers_x,customers_y,s=3, color='red')\n",
    "#ax1.set_title('Customer Locations')\n",
    "\n",
    "\n",
    "#ax2 = fig.add_subplot(122)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "\n",
    "#map_sellers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=80, llcrnrlon=-130, urcrnrlon=30)\n",
    "#map_sellers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "#map_sellers.drawstates(linewidth=0.5)\n",
    "#map_sellers.drawcoastlines(linewidth=0.5)\n",
    "#map_sellers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "#sellers_x, sellers_y = map_sellers(list(geo_df['s_lng']), list(geo_df['s_lat']))\n",
    "\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "#ax2.scatter(sellers_x,sellers_y,s=3,c='tab:orange')\n",
    "#ax2.set_title('Seller Locations')\n",
    "#plt.savefig('images/incorrect_location12345.JPG',bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/incorrect_map_location_2.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: It looks like a few of the shipments went to customers in Portugal. Going to investigate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect value in database investigation\n",
    "\n",
    "Upon further investigation, the shipments that seem to travel to Portugal all have incorrect latitude/longitude coordinates: The zip codes for these locations are being convered to the wrong latitude/longitude coordinates. \n",
    "\n",
    "Note how 'porto trombetas' is a Brazilian city in the state of Para (PR) w/ a zip code prefix of 68275 which actually corresponds to a latitude & longitude of ____. 'areia branca dos assis' is a Brazilian city in the state of Parana w/ a zip code of 83810 which actually corresponds to a latitude & longitude of ____. 'ilha dos valadares' is a Brazilian city in the state of Parana w/ a zip code of 83252 which actually corresponds to a latitude & longitude of ____. It is odd that these latitude/longitude happened to be erroneously converted to latitude/longitude coordinates in Portugal considering both Brazil and Portugal are countries that predominantly speak Portugese.\n",
    "\n",
    "![title](images/incorrect_data.JPG)\n",
    "\n",
    "Will update SQL database w/ the correct latitude/longitude values for these shipments:\n",
    "\n",
    "![title](images/update_83810.JPG)\n",
    "![title](images/update_68275.JPG)\n",
    "![title](images/update_83252.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated map\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "#map_customers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=80, llcrnrlon=-130, urcrnrlon=30)\n",
    "map_customers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "\n",
    "map_customers.drawstates(linewidth=0.5)\n",
    "map_customers.drawcoastlines(linewidth=0.5)\n",
    "map_customers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "customers_x, customers_y = map_customers(list(geo_df['c_lng']), list(geo_df['c_lat']))\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "ax1.scatter(customers_x,customers_y,s=3)\n",
    "ax1.set_title('Customer Locations')\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "map_sellers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "map_sellers.drawstates(linewidth=0.5)\n",
    "map_sellers.drawcoastlines(linewidth=0.5)\n",
    "map_sellers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "sellers_x, sellers_y = map_sellers(list(geo_df['s_lng']), list(geo_df['s_lat']))\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "ax2.scatter(sellers_x,sellers_y,s=3,c='tab:orange')\n",
    "ax2.set_title('Seller Locations')\n",
    "plt.savefig('images/customer_seller_locations.JPG',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#Note that some of the locations are still off: the location that looks to be in Argentina is actually Santa Rosa which is firmly in Brazil. Another case of wrong lat/lng values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "# Will estimate distances using haversine formula\n",
    "# Is approximate b/c this calculates distances between two points on a sphere (Earth is not a perfect sphere)\n",
    "# https://en.wikipedia.org/wiki/Haversine_formula\n",
    "\n",
    "def haversine_dist(lat1,lng1,lat2,lng2):\n",
    "    lat1_rad = lat1*m.pi/180\n",
    "    lng1_rad = lng1*m.pi/180\n",
    "    lat2_rad = lat2*m.pi/180\n",
    "    lng2_rad = lng2*m.pi/180\n",
    "    \n",
    "    dist = 2*3959*m.asin((((m.sin((lat2_rad - lat1_rad)/2))**2) + m.cos(lat1_rad)*m.cos(lat2_rad)*((m.sin((lng2_rad - lng1_rad)/2))**2))**0.5)\n",
    "    \n",
    "    \n",
    "    return dist\n",
    "\n",
    "geo_df['distance_est'] = geo_df.apply(lambda x: haversine_dist(x['c_lat'],x['c_lng'],x['s_lat'],x['s_lng']), axis=1)\n",
    "\n",
    "#Will only work w/ non-missing values for distance and geo-related analysis (441 postal codes fail to be converted to latitude/longitude by USZipCode database)\n",
    "print(len(geo_df[geo_df['distance_est'].isnull()]), ' missing values.')\n",
    "geo_df_nn = geo_df[geo_df['distance_est'].notna()]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "#Histogram of haversine distance values\n",
    "ax1.hist(geo_df_nn['distance_est'], range=(0,2000), bins=10, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "mean_dist = geo_df_nn['distance_est'].mean()\n",
    "median_dist = geo_df_nn['distance_est'].median()\n",
    "ax1.axvline(x=mean_dist,c='red',label='Mean = ' + str(int(round(mean_dist,1))) + ' miles',)\n",
    "ax1.axvline(x=median_dist,c='green',label='Median = ' + str(int(round(median_dist,1))) + ' miles')\n",
    "ax1.set_ylabel('# of \\n shipments',rotation=0, labelpad=50)\n",
    "ax1.set_xlabel('Estimated Distance Traveled (as crow flies, miles)')\n",
    "ax1.set_title('Shipment Estimated Travel Distance Distribution, zoomed in')\n",
    "ax1.set_xticks([0,200,400,600,800,1000,1200,1400,1600,1800,2000])\n",
    "ax1.set_xlim(0,2000)\n",
    "ax1.legend()\n",
    "print('Mean distance traveled (as crow flies, miles): ', mean_dist)\n",
    "print('Median distance traveled (as crow flies, miles): ', median_dist)\n",
    "print(\"Minimum distance traveled (as crows flies, miles): \", geo_df['distance_est'].min())\n",
    "print(\"Maximum distance traveled (as crows flies, miles): \", geo_df['distance_est'].max())\n",
    "print('Number of shipments greater than 2000 miles (as the crow flies, miles): ', len(geo_df[geo_df['distance_est'] > 2000]))\n",
    "\n",
    "plt.savefig('images/Shipment_distance_histogram.JPG',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are the customers placing the most orders?\n",
    "\n",
    "q3 = '''\n",
    "SELECT\n",
    "    c.customer_unique_id,\n",
    "    SUM(oim.price)+SUM(oim.freight_value) total_spent,\n",
    "    COUNT(om.order_id) num_items,\n",
    "    COUNT(DISTINCT(om.order_id)) num_orders\n",
    "FROM orders_modified om\n",
    "INNER JOIN order_items_modified oim ON oim.order_id = om.order_id\n",
    "LEFT JOIN customers c ON c.customer_id = om.customer_id\n",
    "LEFT JOIN geolocation g ON g.geolocation_zip_code = c.customer_zip_code_prefix\n",
    "LEFT JOIN sellers s ON s.seller_id = oim.seller_id\n",
    "LEFT JOIN geolocation g2 ON g2.geolocation_zip_code = s.seller_zip_code_prefix\n",
    "GROUP BY 1\n",
    "ORDER BY 4 DESC\n",
    "LIMIT 10\n",
    "'''\n",
    "\n",
    "run_query(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the shipment paths for the customer who placed the most orders (16)\n",
    "\n",
    "q4 = '''\n",
    "SELECT\n",
    "    c.customer_unique_id,\n",
    "    g.geolocation_lat c_lat,\n",
    "    g.geolocation_lng c_lng,\n",
    "    c.customer_city,\n",
    "    om.order_id,\n",
    "    oim.seller_id,\n",
    "    g2.geolocation_lat s_lat,\n",
    "    g2.geolocation_lng s_lng,\n",
    "    s.seller_city\n",
    "FROM orders_modified om\n",
    "INNER JOIN order_items_modified oim ON oim.order_id = om.order_id\n",
    "LEFT JOIN customers c ON c.customer_id = om.customer_id\n",
    "LEFT JOIN geolocation g ON g.geolocation_zip_code = c.customer_zip_code_prefix\n",
    "LEFT JOIN sellers s ON s.seller_id = oim.seller_id\n",
    "LEFT JOIN geolocation g2 ON g2.geolocation_zip_code = s.seller_zip_code_prefix\n",
    "WHERE c.customer_unique_id IN (\"8d50f5eadf50201ccdcedfb9e2ac8455\")\n",
    "'''\n",
    "\n",
    "run_query(q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "map_customer1 = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "\n",
    "map_customer1.drawstates(linewidth=0.5)\n",
    "map_customer1.drawcoastlines(linewidth=0.5)\n",
    "map_customer1.drawcountries(linewidth=1)\n",
    "\n",
    "\n",
    "df_cust1 = run_query(q4)\n",
    "\n",
    "origin_x, origin_y = map_customer1(list(df_cust1['s_lng']), list(df_cust1['s_lat']))\n",
    "destination_x, destination_y = map_customer1(list(df_cust1['c_lng']),list(df_cust1['c_lat']))\n",
    "\n",
    "\n",
    "# Use numpy.c_ to group arrays into two sets of coordinates: origin coordinates and destination coordinates\n",
    "origin_destination_pairs = np.c_[origin_x, origin_y, destination_x, destination_y].reshape(len(origin_x), 2, 2)\n",
    "\n",
    "# Use LineCollection to plot multiple lines on each graph.\n",
    "# Use add_collection() to add line collection\n",
    "# gca() method uses current axes  (ax1 in this case)\n",
    "plt.gca().add_collection(LineCollection(origin_destination_pairs, color=\"crimson\"))\n",
    "\n",
    "map_customer1.plot(origin_x, origin_y, marker=\"o\", color='orange', linestyle ='', label=\"Seller\")\n",
    "map_customer1.plot(destination_x, destination_y, marker=\"o\", color='blue', linestyle ='', label=\"Customer\")\n",
    "\n",
    "ax1.set_title('Shipping Paths for Most Loyal Customer')\n",
    "ax1.legend()\n",
    "\n",
    "plt.savefig('images/loyal_customer_map.JPG',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "loyal_customer_df = geo_df[geo_df['customer_unique_id']=='8d50f5eadf50201ccdcedfb9e2ac8455']\n",
    "#print(loyal_customer_df)\n",
    "\n",
    "loyal_customer_dist_mean = loyal_customer_df['distance_est'].mean()\n",
    "loyal_customer_dist_median = loyal_customer_df['distance_est'].median()\n",
    "print('Mean distance (miles): ', loyal_customer_dist_mean)\n",
    "print('Median distance (miles): ', loyal_customer_dist_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most loyal customer (highest # of orders of 16) is located in Sao Paulo, Sao Paulo. Their shipments came from sellers in mostly in Sao Paulo, but also Parana and Santa Catarina. The estimated shipment travel distance varied from ~3 miles to ~310 miles. The mean and median estimated shipment travel distance was ~105 miles and ~4 miles, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the shipment path for the shipment that traveled the furthest\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "map_long_ship = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "\n",
    "map_long_ship.drawstates(linewidth=0.5)\n",
    "map_long_ship.drawcoastlines(linewidth=0.5)\n",
    "map_long_ship.drawcountries(linewidth=1)\n",
    "\n",
    "long_ship_df = geo_df[geo_df['distance_est']>2111]\n",
    "\n",
    "origin_x, origin_y = map_long_ship(list(long_ship_df['s_lng']), list(long_ship_df['s_lat']))\n",
    "destination_x, destination_y = map_long_ship(list(long_ship_df['c_lng']),list(long_ship_df['c_lat']))\n",
    "\n",
    "\n",
    "# Use numpy.c_ to group arrays into two sets of coordinates: origin coordinates and destination coordinates\n",
    "origin_destination_pairs = np.c_[origin_x, origin_y, destination_x, destination_y].reshape(len(origin_x), 2, 2)\n",
    "\n",
    "# Use LineCollection to plot multiple lines on each graph.\n",
    "# Use add_collection() to add line collection\n",
    "# gca() method uses current axes  (ax1 in this case)\n",
    "plt.gca().add_collection(LineCollection(origin_destination_pairs, color=\"crimson\"))\n",
    "\n",
    "\n",
    "\n",
    "map_long_ship.plot(origin_x, origin_y, marker=\"o\", color='orange', linestyle ='', label=\"Seller\")\n",
    "map_long_ship.plot(destination_x, destination_y, marker=\"o\", color='blue', linestyle ='', label=\"Customer\")\n",
    "\n",
    "ax1.set_title('Shipping Paths for Longest Shipments')\n",
    "ax1.legend()\n",
    "\n",
    "plt.savefig('images/long_ship_map.JPG',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_ship_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longest shipment was 2112 miles from Fazenda Rio Grande, PR to Boa Vista, RR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urban vs Rural Classification\n",
    "\n",
    "Using 'BRAZIL_CITIES.csv' dataset to classify each customer and seller's location as urban or rural: The 'Brazil_CITIES.csv' dataset contains information on the 5,573 municipalities in Brazil, including their longitude & latitude coordinates. The dataset can be found here: https://www.kaggle.com/crisparada/brazilian-cities. The dataset was compiled from a variety of sources but mainly the IBGE (Brazilian Institute of Geography and Statistics). There is a column in this dataset that marks each municipality as urban or not according to the IBGE. Filtered dataset down to the 1,456 municipalities that are classified as urban by the IBGE. \n",
    "\n",
    "Built function (urban_feature_function) that will match each row in the geolocation table (each row corresponds to a unique zip code) to the nearest urban municipality (calling these cities). The function also calculates the distance to this city, and if it is close enough to this city (within 20 miles), whether this zip code is in an urban area or not. The function works by using my distance function that I created earlier in this section. For each zip code in the geolocation table, the distance to each of the 1,456 cities is calculated. The closest urban city is found by finding the city with the minimum distance. This process is repeated for all 19,000+ unique zip codes in the geolocation table. \n",
    "\n",
    "These new features are then added to the geolocation dataframe. This data is exported as a csv file and then inserted into a new table, called geolocation_updated.\n",
    "\n",
    "Now for each customer and seller, the nearest urban city, the distance to that city and whether their location is urban or not is now known. This information can be used for each order as well: Whether the shipment was from one urban location to another urban location, whether each shipment was from a rural location to a rural location etc. Also whether the shipment was within the same urban location. \n",
    "\n",
    "<b> Problem: \" The criteria used by the IBGE (Brazilian Institute of Geography and Statistics)[2] in determining whether households are urban or rural, however, are based on political divisions, not on the built environment.\" https://en.wikipedia.org/wiki/List_of_largest_cities_in_Brazil#cite_note-WorldBank-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cities_df = pd.read_csv('BRAZIL_CITIES.csv',delimiter=';')\n",
    "cities_df = cities_df.sort_values(by='IBGE_RES_POP', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_df = cities_df[cities_df['RURAL_URBAN']=='Urbano']\n",
    "urban_df.reset_index(drop=True, inplace=True)\n",
    "print('Number of municipalties in this dataset: ', len(cities_df))\n",
    "print('Number of municipalities classified as urban in this dataset: ', len(urban_df))\n",
    "urban_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated map\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "#map_customers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=80, llcrnrlon=-130, urcrnrlon=30)\n",
    "map_urban = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "\n",
    "map_customers.drawstates(linewidth=0.5)\n",
    "map_customers.drawcoastlines(linewidth=0.5)\n",
    "map_customers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "urban_x, urban_y = map_customers(list(urban_df['LONG']), list(urban_df['LAT']))\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "ax1.scatter(urban_x, urban_y,s=3)\n",
    "ax1.set_title('Urban Locations')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Note that some of the locations are still off: the location that looks to be in Argentina is actually Santa Rosa which is firmly in Brazil. Another case of wrong lat/lng values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urban_df[urban_df['LAT'].isnull()]))\n",
    "print(len(urban_df[urban_df['LONG'].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = '''\n",
    "SELECT *\n",
    "FROM geolocation\n",
    "'''\n",
    "\n",
    "geolocation_table = run_query(q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that creates feature \"urban\":\n",
    "\n",
    "# Apply function to each row in the dataframe. For each row:\n",
    "# Loop through each row in urban_df. Calculate Haversine Distance. If Haversine Distance < 25 miles, set urban_df value to 1 and end loop\n",
    "# Else, keep going through each row in urban_df. If the customer/seller isn't within 25 miles of any of the 1,500 urban areas, it will have a value of 0 for rural.\n",
    "\n",
    "\n",
    "def urban_feature_function(df_row):\n",
    "\n",
    "    lat = df_row['geolocation_lat']\n",
    "    lng = df_row['geolocation_lng']\n",
    "    distance_series = urban_df.apply(lambda x: haversine_dist(x['LAT'],x['LONG'], lat, lng), axis=1)\n",
    "    closest_index = distance_series.idxmin()\n",
    "    closest_distance = distance_series[closest_index]\n",
    "    closest_city = urban_df.loc[closest_index,'CITY']\n",
    "    urban=0\n",
    "    if closest_distance < 20:\n",
    "        urban =1 \n",
    "\n",
    "    return (closest_city, closest_distance, urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I have commented out the cell below b/c it takes a long time to run (~940 seconds the last time it was ran) and doesn't need to be run multiple times. The result was inserted into the file 'geolocation_updated.csv'. And then inserted into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "#start = time.time()\n",
    "\n",
    "#urban_series = geolocation_table.apply(lambda x: urban_feature_function(x), axis=1)\n",
    "\n",
    "#urban_df = pd.DataFrame(urban_series.tolist(), index=geolocation_table.index).rename(columns={0:'Closest_Urban_City', 1:'Urban_City_Distance', 2:'Urban'}) \n",
    "#geolocation_table_updated = pd.concat([geolocation_table, urban_df], axis=1)\n",
    "\n",
    "#geolocation_table_updated.to_csv('data/brazilian-ecommerce/geolocation_updated.csv', index=False)\n",
    "\n",
    "#end = time.time()\n",
    "#time_amount = end - start\n",
    "#print(time_amount, ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geolocation_table_updated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocation_table_updated = pd.read_csv('data/brazilian-ecommerce/geolocation_updated.csv')\n",
    "\n",
    "geolocation_table_updated.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Create new, updated geolocation table w/ the additional fields Closest_Urban_City, Urban_City_Distance and Urban</b>:<br>\n",
    "Create geolocation_updated table: \n",
    "![title](images/geolocation_updated.JPG)\n",
    "\n",
    "Insert data into geolocation_updated table:\n",
    "![title](images/insert_geolocation_updated.JPG)\n",
    "\n",
    "\n",
    "<b>Added new foreign key to sellers table </b>: <br>\n",
    "\n",
    "<b>Special note(s)</b>: \n",
    "1. SQLite lacks the functionality to alter existing table and add foreign key. Have to add foreign key to table the long way (see below).\n",
    "2. Ran commands through run_command function rather than through DB Browser b/c the run_command function does a much better job of managing the connection to the database (there is only a connection to the database when the run_command function is running, similar to the run_query function). Using the DB Browser for these tasks resulted in the program either crashing or returning \"data base disk image is malformed\".\n",
    "![title](images/run_command_function.JPG)\n",
    "3. Note that creating a new foreign key for the customers and sellers tables to the new geolocation_updated table is not an absolute necessity: can join non-foreign key to non-primary key fields but w/o these constraints, not guaranteed to maintain data integrity so this would require one to be very careful.\n",
    "\n",
    "\n",
    "drop table sellers:\n",
    "![title](images/drop_table_sellers_final.JPG)\n",
    "create table sellers w/ new foreign key:\n",
    "![title](images/create_table_sellers_new_fk_final.JPG) \n",
    "insert sellers data from csv:\n",
    "![title](images/insert_data_sellers.JPG) \n",
    "drop header row from sellers table:\n",
    "![title](images/sellers_drop_header_final.JPG) \n",
    "\n",
    "\n",
    "<b>Added new foreign key to customers table</b>: <br>\n",
    "\n",
    "drop table customers:\n",
    "![title](images/drop_table_customers.JPG) \n",
    "create table customers w/ new foreign key:\n",
    "![title](images/create_table_customers_new_fk.JPG) \n",
    "insert customers data from csv:\n",
    "![title](images/insert_data_customers.JPG) \n",
    "drop header row from customers table:\n",
    "![title](images/delete_header_customers.JPG)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create manager to handle queries that don't return tables (ie commands, not queries) like for creating views.\n",
    "# Manages connection to database such that the database is only connected when this function is running (same as run_query function)\n",
    "def run_command(c):\n",
    "    with sqlite3.connect('data/ecommerce.db') as conn:\n",
    "        conn.isolation_level=None\n",
    "        conn.execute(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out all commands b/c only want to run commands once ever\n",
    "\n",
    "#q_command_1 = '''\n",
    "#DROP TABLE IF EXISTS sellers\n",
    "#'''\n",
    "\n",
    "#run_command(q_command_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_tables = '''\n",
    "#SELECT name, sql FROM sqlite_master\n",
    "#WHERE type='table'\n",
    "#ORDER BY name;\n",
    "#'''\n",
    "\n",
    "#run_query(q_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_command_2 = '''\n",
    "#CREATE TABLE 'sellers' (\n",
    "#    'seller_id' [TEXT] PRIMARY KEY,\n",
    "#    'seller_zip_code_prefix' [INTEGER],\n",
    "#    'seller_city' [TEXT],\n",
    "#    'seller_state' [TEXT],\n",
    "#    FOREIGN KEY ('seller_zip_code_prefix')\n",
    "#        REFERENCES geolocation ('geolocation_zip_code'),\n",
    "#    FOREIGN KEY ('seller_zip_code_prefix')\n",
    "#        REFERENCES geolocation_updated ('geolocation_zip_code')\n",
    "#    );\n",
    "#'''\n",
    "\n",
    "#run_command(q_command_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop header row\n",
    "\n",
    "#q_command_3 = '''\n",
    "#DELETE FROM sellers\n",
    "#WHERE seller_id='seller_id';\n",
    "#'''\n",
    "\n",
    "#run_command(q_command_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_command_4 = '''\n",
    "#DROP TABLE IF EXISTS customers\n",
    "#'''\n",
    "\n",
    "#run_command(q_command_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customers table w/ new foreign key\n",
    "\n",
    "#q_command_5 = '''\n",
    "#CREATE TABLE 'customers' (\n",
    "#    'customer_id' [TEXT] PRIMARY KEY,\n",
    "#    'customer_unique_id' [TEXT],\n",
    "#    'customer_zip_code_prefix' [INTEGER],\n",
    "#    'customer_city' [TEXT],\n",
    "#    'customer_state' [TEXT],\n",
    "#    FOREIGN KEY ('customer_zip_code_prefix')\n",
    "#        REFERENCES geolocation ('geolocation_zip_code'),\n",
    "#    FOREIGN KEY ('customer_zip_code_prefix')\n",
    "#        REFERENCES geolocation_updated ('geolocation_zip_code')\n",
    "#    );\n",
    "#'''\n",
    "\n",
    "#run_command(q_command_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop header row\n",
    "\n",
    "#q_command_6 = '''\n",
    "#DELETE FROM customers\n",
    "#WHERE customer_id='customer_id';\n",
    "#'''\n",
    "\n",
    "#run_command(q_command_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New geo_df w/ the three new urban features: \n",
    "\n",
    "q5 = '''\n",
    "SELECT \n",
    "    c.*,\n",
    "    g.geolocation_lat c_lat,\n",
    "    g.geolocation_lng c_lng,\n",
    "    g.Closest_Urban_City Customer_Urban_City,\n",
    "    g.Urban_City_Distance Customer_Urban_Distance,\n",
    "    g.Urban Customer_Urban,\n",
    "    merged.*,\n",
    "    s.*,\n",
    "    g2.geolocation_lat s_lat,\n",
    "    g2.geolocation_lng s_lng,\n",
    "    g2.Closest_Urban_City Seller_Urban_City,\n",
    "    g2.Urban_City_Distance Seller_Urban_Distance,\n",
    "    g2.Urban Seller_Urban\n",
    "FROM (\n",
    "    SELECT *\n",
    "    FROM orders_modified om\n",
    "    LEFT JOIN order_items_modified oim ON oim.order_id=om.order_id\n",
    "    GROUP BY om.order_id\n",
    "    ) as merged\n",
    "LEFT JOIN customers c ON c.customer_id = merged.customer_id\n",
    "LEFT JOIN geolocation_updated g ON g.geolocation_zip_code = c.customer_zip_code_prefix\n",
    "LEFT JOIN sellers s ON s.seller_id = merged.seller_id\n",
    "LEFT JOIN geolocation_updated g2 ON g2.geolocation_zip_code = s.seller_zip_code_prefix\n",
    "WHERE merged.order_status='delivered' AND length(c_lat)>0 AND length(s_lat)>0\n",
    "'''\n",
    "\n",
    "geo_df_updated = run_query(q5)\n",
    "geo_df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in geo_df: ', len(geo_df))\n",
    "print('Number of rows in geo_df_updated: ', len(geo_df_updated))\n",
    "\n",
    "print('Results of table_audit_function for geo_df:')\n",
    "table_audit_function(geo_df)\n",
    "print('Results of table_audit_function for geo_df_updated:')\n",
    "table_audit_function(geo_df_updated)\n",
    "\n",
    "print('\\nConclusion: These two dataframes are identifical except geo_df_updated has six new urban features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urban/rural location composition for customers:\n",
    "\n",
    "q6 = '''\n",
    "SELECT \n",
    "    COUNT(DISTINCT(c.customer_unique_id)) num_customers,\n",
    "    gu.Urban\n",
    "FROM customers c\n",
    "LEFT JOIN geolocation_updated gu ON gu.geolocation_zip_code=c.customer_zip_code_prefix\n",
    "GROUP BY 2\n",
    "'''\n",
    "\n",
    "run_query(q6)\n",
    "\n",
    "# Make urban / rural / unknown pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_urban_comp = run_query(q6)\n",
    "customer_urban_comp = customer_urban_comp.loc[1:]\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "label = ['Rural', 'Urban']\n",
    "\n",
    "ax1.pie(x=customer_urban_comp['num_customers'], labels=label, autopct='%1.1f%%', explode=(0,0.1))\n",
    "ax1.set_title(\"Customer Urban-Rural Composition\")\n",
    "plt.savefig('images/customer_urban_rural.JPG',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.2% of the Olist customers are located in urban areas. This matches pretty closely with the overall Brazilian urban composition (by population) as of 2018 of 86.6% (Source: https://data.worldbank.org/indicator/SP.URB.TOTL.IN.ZS?locations=BR). It makes intuitive sense that the urban-rural composition would be higher than that considering that individuals in rural areas are probably less likely to use ecommerce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urban/rural location composition for sellers:\n",
    "\n",
    "q7 = '''\n",
    "SELECT \n",
    "    COUNT(DISTINCT(s.seller_id)) num_sellers,\n",
    "    gu.Urban\n",
    "FROM sellers s\n",
    "LEFT JOIN geolocation_updated gu ON gu.geolocation_zip_code=s.seller_zip_code_prefix\n",
    "GROUP BY 2\n",
    "'''\n",
    "\n",
    "run_query(q7)\n",
    "\n",
    "# Make urban / rural / unknown pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_urban_comp = run_query(q7)\n",
    "seller_urban_comp = seller_urban_comp.loc[1:]\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "label = ['Rural', 'Urban']\n",
    "\n",
    "ax1.pie(x=seller_urban_comp['num_sellers'], labels=label, autopct='%1.1f%%', explode=(0,0.1))\n",
    "ax1.set_title(\"Seller Urban-Rural Composition\")\n",
    "plt.savefig('images/seller_urban_rural.JPG',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.2% of the Olist sellers are located in urban areas. This makes intuitive sense considering the overall Brazilian urban-rural composition (by population) as of 2018 is 86.7% and the fact that businesses are probably more likely to be in urban areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "# Customers\n",
    "customer_urban_comp = run_query(q6)\n",
    "customer_urban_comp = customer_urban_comp.loc[1:]\n",
    "label = ['Rural', 'Urban']\n",
    "ax1.pie(x=customer_urban_comp['num_customers'], autopct='%1.1f%%', explode=(0,0.1))\n",
    "ax1.set_title(\"Customers\", size=20)\n",
    "\n",
    "#Sellers\n",
    "seller_urban_comp = run_query(q7)\n",
    "seller_urban_comp = seller_urban_comp.loc[1:]\n",
    "\n",
    "\n",
    "ax2.pie(x=seller_urban_comp['num_sellers'], autopct='%1.1f%%', explode=(0,0.1))\n",
    "ax2.set_title(\"Sellers\", size=20)\n",
    "plt.savefig('images/customer_seller_urban_rural.JPG',bbox_inches='tight')\n",
    "plt.legend(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_urban_urban = len(geo_df_updated[(geo_df_updated['Seller_Urban']==1) & (geo_df_updated['Customer_Urban']==1)])\n",
    "print(num_urban_urban)\n",
    "num_urban_rural = len(geo_df_updated[(geo_df_updated['Seller_Urban']==1) & (geo_df_updated['Customer_Urban']==0)])\n",
    "print(num_urban_rural)\n",
    "num_rural_urban = len(geo_df_updated[(geo_df_updated['Seller_Urban']==0) & (geo_df_updated['Customer_Urban']==1)])\n",
    "print(num_rural_urban)\n",
    "num_rural_rural = len(geo_df_updated[(geo_df_updated['Seller_Urban']==0) & (geo_df_updated['Customer_Urban']==0)])\n",
    "print(num_rural_rural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "urban_comp_shipments = [num_urban_urban, num_urban_rural, num_rural_urban, num_rural_rural]\n",
    "label = ['Urban Seller to Urban Customer', 'Urban Seller to Rural Customer', 'Rural Seller to Urban Customer', 'Rural Seller to Rural Customer']\n",
    "\n",
    "ax1.pie(x=urban_comp_shipments , labels=label, autopct='%1.1f%%', explode=(0,0,0,2))\n",
    "ax1.set_title(\"Urban-Rural Shipment Composition\")\n",
    "plt.savefig('images/urban_shipments.JPG',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority (96.0%) of the delivered shipments are from an urban seller to an urban customer. <br>\n",
    "3.8% of the delivered shipments are from an urban seller to a rural customer. <br>\n",
    "Rural to urban and rural to rural delivered shipments are virtually non-existent (0.2% and 0.008%, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated map for urban vs rural classification for customers and sellers.\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "\n",
    "map_customers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "\n",
    "map_customers.drawstates(linewidth=0.5)\n",
    "map_customers.drawcoastlines(linewidth=0.5)\n",
    "map_customers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "urban_customers_x, urban_customers_y = map_customers(list(geo_df_updated.loc[geo_df_updated['Customer_Urban']==1,'c_lng']), list(geo_df_updated.loc[geo_df_updated['Customer_Urban']==1,'c_lat']))\n",
    "rural_customers_x, rural_customers_y = map_customers(list(geo_df_updated.loc[geo_df_updated['Customer_Urban']==0,'c_lng']), list(geo_df_updated.loc[geo_df_updated['Customer_Urban']==0,'c_lat']))\n",
    "\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "ax1.scatter(urban_customers_x, urban_customers_y, s=2,c='tab:purple')\n",
    "ax1.scatter(rural_customers_x, rural_customers_y,s=2, c='tab:green')\n",
    "\n",
    "ax1.set_title('Customer Locations')\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "#1. create a new basemap instance with the specific map projection we want and how much of the map we want included:\n",
    "#Using the Basemap() constructor\n",
    "map_sellers = Basemap(projection='merc', llcrnrlat=-60, urcrnrlat=20, llcrnrlon=-85, urcrnrlon=-30)\n",
    "map_sellers.drawstates(linewidth=0.5)\n",
    "map_sellers.drawcoastlines(linewidth=0.5)\n",
    "map_sellers.drawcountries(linewidth=1)\n",
    "\n",
    "#2. convert spherical coordinates to cartesian coordinates using the basemap instance\n",
    "urban_sellers_x, urban_sellers_y = map_customers(list(geo_df_updated.loc[geo_df_updated['Seller_Urban']==1,'s_lng']), list(geo_df_updated.loc[geo_df_updated['Seller_Urban']==1,'s_lat']))\n",
    "rural_sellers_x, rural_sellers_y = map_customers(list(geo_df_updated.loc[geo_df_updated['Seller_Urban']==0,'s_lng']), list(geo_df_updated.loc[geo_df_updated['Seller_Urban']==0,'s_lat']))\n",
    "\n",
    "#3. Plot cartesian coordinates\n",
    "ax2.scatter(urban_sellers_x, urban_sellers_y, s=2,c='tab:purple',label='Urban')\n",
    "ax2.scatter(rural_sellers_x, rural_sellers_y,s=2, c='tab:green',label='Rural')\n",
    "\n",
    "ax2.set_title('Seller Locations')\n",
    "ax2.legend(markerscale=8)\n",
    "plt.savefig('images/customer_seller_locations_urban.JPG',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_same = len(geo_df_updated[(geo_df_updated['Seller_Urban_City']==geo_df_updated['Customer_Urban_City'])&(geo_df_updated['Customer_Urban']==1)&(geo_df_updated['Seller_Urban']==1)])\n",
    "print('Number of shipments that stay within the same metropolitan area:',num_same)\n",
    "# 1,529 of the shipments occur within the same urban city.\n",
    "\n",
    "#Do same analysis for the 28 metropolitan areas??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metropolitan_areas_list = [São Paulo, Rio de Janeiro, Belo Horizonte, Brasilia, Porto Alegre, Fortaleza\t Ceará\t4,051,744\t4,019,213\t+0.8%\n",
    "7\tSalvador\t Bahia\t4,015,205\t3,984,583\t+0.8%\n",
    "8\tRecife\t Pernambuco\t3,965,699\t3,940,456\t+0.6%\n",
    "9\tCuritiba\t Paraná\t3,572,326\t3,537,894\t+1.0%\n",
    "10\tCampinas\t São Paulo\t3,168,019\t3,131,528\t+1.2%\n",
    "11\tManaus\t Amazonas\t2,612,747\t2,568,817\t+1.7%\n",
    "12\tVale do Paraíba e Litoral Norte (São José dos Campos)\t São Paulo\t2,497,857\t2,475,879\t+0.9%\n",
    "13\tGoiânia\t Goiás\t2,493,792\t2,458,504\t+1.4%\n",
    "14\tBelém\t Pará\t2,441,761\t2,422,481\t+0.8%\n",
    "15\tSorocaba\t São Paulo\t2,088,381\t1,908,425\t+9.4%\n",
    "16\tVitória\t Espírito Santo\t1,960,213\t1,935,483\t+1.3%\n",
    "17\tBaixada Santista (Santos)\t São Paulo\t1,828,212\t1,813,033\t+0.8%\n",
    "18\tRibeirão Preto\t São Paulo\t1,678,910\t1,662,645\t+1.0%\n",
    "19\tSão Luís\t Maranhão\t1,619,377\t1,605,305\t+0.9%\n",
    "20\tNatal\t Rio Grande do Norte\t1,596,104\t1,537,211\t+3.8%\n",
    "21\tPiracicaba\t São Paulo\t1,464,993\t1,452,691\t+0.8%\n",
    "22\tNorte/Nordeste Catarinense (Joinville)\t Santa Catarina\t1,383,456\t1,363,854\t+1.4%\n",
    "23\tMaceió\t Alagoas\t1,352,241\t1,314,254\t+2.9%\n",
    "24\tJoão Pessoa\t Paraíba\t1,282,227\t1,268,360\t+1.1%\n",
    "25\tTeresina\t Piauí / Maranhão\t1,204,397\t1,199,941\t+0.4%\n",
    "26\tFlorianópolis\t Santa Catarina\t1,172,076\t1,152,115\t+1.7%\n",
    "27\tLondrina\t Paraná\t1,094,347\t1,085,479\t+0.8%\n",
    "28\tVale do Rio Cuiabá (Cuiabá)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urban_df['REGIAO_TUR'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do for ecommerce.db (save ecommerce.db copy first in separate folder)\n",
    "# Do in new file\n",
    "# Document every single step along the way w/ snippets. Paste all snippets into markdown above.\n",
    "# End result is now sellers and customers can join geolocation_updated while preserving data integrity.\n",
    "\n",
    "# Will have to do same procedure when do new features like google maps API distance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
